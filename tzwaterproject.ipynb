{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] *Business Problem:*\n",
    "  - [ ] 1.1 Background\n",
    "  - [ ] 1.2 Problem Statement\n",
    "\n",
    "- [ ] *Import Libraries*\n",
    "\n",
    "- [ ] *Data Exploration:*\n",
    "  - [ ] 3.1 Data Fields\n",
    "\n",
    "- [ ] *Data Preparation:*\n",
    "  - [ ] 4.1 Missing Values\n",
    "    - [ ] 4.1.1 `tunir`\n",
    "    - [ ] 4.1.2 Model reiteration-parameter `tuni`\n",
    "    - [ ] 4.1.3 `permit`\n",
    "    - [ ] 4.1.4 `construction year`\n",
    "  - [ ] 4.2 Replace misspellings and group smaller categories\n",
    "    - [ ] 4.2.1 Reformat `Installer` column\n",
    "    - [ ] 4.2.2 Reformat `Funder` column\n",
    "    - [ ] 4.2.3 Group Other Remaining Columns\n",
    "      - [ ] 4.2.3.1 Iga\n",
    "  - [ ] 4.3 Columns to drop\n",
    "    - [ ] 4.3.1 Mostly Empty\n",
    "    - [ ] 4.3.2 Many Individual Values\n",
    "    - [ ] 4.3.3 Not Significant\n",
    "      - [ ] 4.3.3.1 The features scheme manage\n",
    "    - [ ] 4.3.4 Categorical and Numerical\n",
    "  - [ ] 4.4 Join Target: `df_train` set to `df_train`\n",
    "  - [ ] 4.5 Column Binning\n",
    "  - [ ] 4.6 Clean Target\n",
    "  - [ ] 4.7 Visualizations\n",
    "\n",
    "- [ ] *Train Test Split*\n",
    "\n",
    "- [ ] *Encode Features*\n",
    "  - [ ] 6.1 X train Encode\n",
    "  - [ ] 6.2 X test Encode\n",
    "  - [ ] 6.3 Delete 'other' columns OHE\n",
    "    - [ ] 6.3.1 Delete Other Train\n",
    "    - [ ] 6.3.2 Delete Other Test\n",
    "  - [ ] 6.4 Label Encode Target\n",
    "\n",
    "- [ ] *Model Development*\n",
    "  - [ ] 7.1 Random Forest Classifier\n",
    "    - [ ] 7.1.1 Check for Overfit\n",
    "    - [ ] 7.1.2 Feature Importance\n",
    "    - [ ] 7.1.3 Model reiteration-parameter\n",
    "  - [ ] 7.2 Gradient Boosting Classifier\n",
    "    - [ ] 7.2.1 Check for Overfit\n",
    "  - [ ] 7.3 Logistic Regression\n",
    "    - [ ] 7.3.1 Unbalanced\n",
    "    - [ ] 7.3.2 Balanced\n",
    "    - [ ] 7.3.3 Check for Overfit\n",
    "    - [ ] 7.3.4 Model reiteration - parameter tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Business Problem:\n",
    "\n",
    "## 1.1 Problem statement\n",
    "* The inadequate provision of clean water in Tanzania poses a significant challenge for the country's population of over 57 million. The existing waterpoints in Tanzania include wells that are in need of repair or have completely failed. To address this issue, there is a need to develop a classifier that can predict the condition of water wells based on various factors such as the type of pump used, installation date, and other relevant information._\n",
    "\n",
    "\n",
    "* The business problem at hand is to create a robust classifier that can accurately classify the condition of water wells in Tanzania into three categories: wells in need of repair, failed wells, and wells that are in good condition. This classifier can be valuable for decision-makers, government bodies, and non-profit organizations working towards providing clean and sustainable water solutions in Tanzania._\n",
    "\n",
    "* By accurately predicting the condition of water wells, stakeholders can prioritize repair and maintenance efforts, allocate resources effectively, and implement preventive measures to ensure a reliable supply of clean water to the population. Additionally, the classifier can assist in identifying patterns and factors that contribute to the deterioration of water wells, allowing for targeted interventions and long-term planning to improve the overall water infrastructure in Tanzania."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i will have to write the features I will be using to create the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  Importing the libraries required for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" from sklearn.linear_model import LinearRegression\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport matplotlib.ticker as mtick\\nimport seaborn as sns\\nimport numpy as np\\nimport scipy.stats as stats\\nimport statsmodels.api as sm\\n# import xgboost as xgb\\nimport catboost\\nimport time\\nimport warnings\\nwarnings.filterwarnings('ignore')\\n\\nfrom sklearn.utils import class_weight\\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\\nfrom catboost import Pool, sum_models\\nfrom catboost import CatBoostClassifier\\nfrom statsmodels.formula.api import ols\\nfrom sklearn.feature_selection import RFE\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, balanced_accuracy_score\\nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\\nfrom sklearn.preprocessing import LabelEncoder,  OneHotEncoder\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler \\n\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report, confusion_matrix\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn import metrics\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom scipy.stats import uniform, truncnorm, randint\\nfrom sklearn.preprocessing import OneHotEncoder\\nfrom sklearn.preprocessing import LabelEncoder \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "# import xgboost as xgb\n",
    "import catboost\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from catboost import Pool, sum_models\n",
    "from catboost import CatBoostClassifier\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, balanced_accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder,  OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries required for the project\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
